{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de texte avec RandomForest et TF-IDF\n",
    "Ce notebook présente une solution complète pour la classification de textes, en utilisant le prétraitement linguistique avec SpaCy, la vectorisation TF-IDF et un modèle RandomForest.\n",
    "\n",
    "Chaque étape est expliquée en français."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et préparation des données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Chargement des données d'entraînement\n",
    "with open('train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "df = pd.DataFrame(train_data)\n",
    "df['description'] = df['description'].fillna(\"\")  # Remplacement des valeurs manquantes"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage et lemmatisation des descriptions avec SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Chargement du modèle SpaCy (assurez-vous que 'en_core_web_lg' est installé)\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def clean_and_tokenize(text):\n",
    "    \"\"\"\n",
    "    Nettoie et lemmatise un texte :\n",
    "    - enlève le HTML et les liens\n",
    "    - met en minuscules\n",
    "    - enlève les stopwords et tokens non alphabétiques\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "    text = text.lower().strip()\n",
    "    doc = nlp(text)\n",
    "    tokens = [tok.lemma_ for tok in doc if tok.is_alpha and not tok.is_stop]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['Clean'] = df['description'].apply(clean_and_tokenize)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et fusion des labels"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "labels_df = pd.read_csv('train_label.csv')\n",
    "df = df.merge(labels_df, on='Id')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation des textes avec TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tfidf = TfidfVectorizer(max_features=20000, ngram_range=(1,2), min_df=5, norm='l2')\n",
    "X_tfidf = tfidf.fit_transform(df['Clean'])\n",
    "y = df['Category']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données en ensembles d'entraînement et de validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=30, random_state=42, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_val)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation du modèle sur l'ensemble de validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(classification_report(y_val, y_pred))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction sur les données de test et génération du fichier de soumission"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Chargement des données de test\n",
    "with open('test.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df['description'] = test_df['description'].fillna(\"\")\n",
    "test_df['Clean'] = test_df['description'].apply(clean_and_tokenize)\n",
    "\n",
    "# Vectorisation des données de test\n",
    "X_test = tfidf.transform(test_df['Clean'])\n",
    "\n",
    "# Prédiction\n",
    "preds = rf_clf.predict(X_test)\n",
    "\n",
    "# Génération du fichier de soumission\n",
    "template = pd.read_csv('template_submissions.csv')\n",
    "template['Category'] = template['Id'].map(dict(zip(test_df['Id'], preds)))\n",
    "template.to_csv('submission_rf.csv', index=False)\n",
    "print(\"Fichier de soumission enregistré : 'submission_rf.csv'\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}