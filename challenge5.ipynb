{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de texte avec embeddings SpaCy et régression logistique\n",
    "\n",
    "Ce notebook détaille un pipeline complet de classification de texte utilisant les embeddings pré-entraînés de SpaCy (en_core_web_lg) et la régression logistique. Chaque étape est expliquée, du prétraitement à la génération du fichier de soumission.\n",
    "\n",
    "---\n",
    "\n",
    "## Concepts clés\n",
    "\n",
    "- **Embeddings SpaCy** : chaque texte est représenté par un vecteur dense (300 dimensions) issu d'un modèle pré-entraîné, capturant la sémantique globale du texte.\n",
    "- **Régression logistique** : modèle linéaire de classification multi-classes, qui prédit la probabilité d'appartenance à chaque classe.\n",
    "- **Prétraitement linguistique** : nettoyage léger pour améliorer la qualité des features.\n",
    "- **Train/Test split** : séparation des données pour évaluer la capacité de généralisation du modèle.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et nettoyage des données\n",
    "\n",
    "On charge les données d'entraînement depuis un fichier JSON. On remplace les valeurs manquantes dans la colonne 'description' par une chaîne vide pour éviter les erreurs lors du traitement."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "with open('train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "df = pd.DataFrame(train_data)\n",
    "df['description'] = df['description'].fillna(\"\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement du modèle SpaCy large (en_core_web_lg)\n",
    "\n",
    "On utilise le modèle SpaCy large, qui fournit des embeddings de 300 dimensions pour chaque texte. Ces vecteurs sont appris sur de grands corpus et capturent la similarité sémantique entre textes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Assure-toi d'avoir exécuté : python -m spacy download en_core_web_lg\n",
    "nlp = spacy.load('en_core_web_lg')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fonction de nettoyage et vectorisation\n",
    "\n",
    "On définit une fonction qui :\n",
    "- enlève le HTML et les URLs\n",
    "- met en minuscules\n",
    "- passe le texte dans SpaCy pour obtenir le vecteur global (`doc.vector`)\n",
    "\n",
    "Le vecteur retourné est la moyenne des embeddings des tokens du texte (dimension 300)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def clean_and_vectorize(text):\n",
    "    txt = re.sub(r'<[^>]+>', ' ', text)\n",
    "    txt = re.sub(r'http\\S+', ' ', txt)\n",
    "    txt = txt.lower().strip()\n",
    "    doc = nlp(txt)\n",
    "    return doc.vector"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Création de la matrice de features\n",
    "\n",
    "On applique la fonction à chaque description pour obtenir une matrice $(n_{samples}, 300)$ où chaque ligne est le vecteur du texte. On charge aussi les labels associés à chaque Id."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "vectors = np.vstack(df['description'].apply(clean_and_vectorize).values)\n",
    "y = pd.read_csv('train_label.csv').set_index('Id').loc[df['Id'], 'Category'].values"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Séparation train/validation\n",
    "\n",
    "On sépare les données en un ensemble d'entraînement (80%) et de validation (20%) pour évaluer la capacité de généralisation du modèle. On stratifie pour conserver la proportion des classes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    vectors, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entraînement du modèle de régression logistique\n",
    "\n",
    "La régression logistique est un modèle linéaire de classification multi-classes. Elle apprend un hyperplan de séparation dans l'espace des embeddings.\n",
    "\n",
    "Mathématiquement, pour chaque classe $k$ :\n",
    "$$ P(y=k|x) = \\frac{\\exp(w_k^T x + b_k)}{\\sum_j \\exp(w_j^T x + b_j)} $$\n",
    "où $x$ est le vecteur du texte, $w_k$ et $b_k$ sont les paramètres appris pour la classe $k$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "clf = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Évaluation du modèle\n",
    "\n",
    "On prédit les classes sur l'ensemble de validation et on affiche un rapport de classification (précision, rappel, F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prédiction sur les données de test\n",
    "\n",
    "On applique le même prétraitement et la même vectorisation aux textes de test, puis on prédit la catégorie pour chaque texte."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "with open('test.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_vectors = np.vstack(test_df['description'].apply(clean_and_vectorize).values)\n",
    "preds = clf.predict(test_vectors)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Génération du fichier de soumission\n",
    "\n",
    "On prépare le fichier de soumission au format attendu, associant chaque Id de test à la catégorie prédite."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "template = pd.read_csv('template_submissions.csv')\n",
    "template['Category'] = template['Id'].map(dict(zip(test_df['Id'], preds)))\n",
    "template.to_csv('submission_spacy_lg.csv', index=False)\n",
    "print(\"Saved submission as 'submission_spacy_lg.csv'\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concepts mathématiques et conclusion\n",
    "\n",
    "- **Embeddings SpaCy** : chaque texte est représenté par un vecteur dense de 300 dimensions, qui capture la sémantique globale du texte.\n",
    "- **Régression logistique** : le modèle apprend à séparer les classes dans l'espace vectoriel des textes, en maximisant la probabilité des bonnes classes.\n",
    "- **Classification** : la sortie du modèle est la classe avec la probabilité la plus élevée.\n",
    "\n",
    "Ce pipeline montre comment passer de textes bruts à des prédictions de classes avec un modèle linéaire, en utilisant des représentations vectorielles avancées."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}