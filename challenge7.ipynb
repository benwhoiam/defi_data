{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de texte optimisée avec TF-IDF et SVM (GridSearch)\n",
    "\n",
    "Ce notebook détaille un pipeline avancé de classification de texte utilisant le prétraitement linguistique avec SpaCy, la vectorisation TF-IDF, un SVM linéaire, et une optimisation des hyperparamètres par GridSearchCV. Chaque étape est expliquée, du nettoyage à la génération du fichier de soumission.\n",
    "\n",
    "---\n",
    "\n",
    "## Concepts clés\n",
    "\n",
    "- **TF-IDF** : pondère chaque mot selon sa fréquence dans le document et sa rareté dans le corpus.\n",
    "- **SVM linéaire** : cherche l'hyperplan qui sépare au mieux les classes dans l'espace vectoriel.\n",
    "- **GridSearchCV** : recherche systématique des meilleurs hyperparamètres par validation croisée.\n",
    "- **Macro-F1** : mesure la performance globale en équilibrant l'importance de chaque classe.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et préparation des données\n",
    "\n",
    "On charge les données d'entraînement et les labels, puis on fusionne les deux. Les descriptions manquantes sont remplacées par une chaîne vide."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "with open('train.json','r',encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "df = pd.DataFrame(train_data).fillna({'description':\"\"})\n",
    "labels = pd.read_csv('train_label.csv')\n",
    "df = df.merge(labels, on='Id')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nettoyage et lemmatisation des textes\n",
    "\n",
    "On utilise SpaCy pour nettoyer et lemmatiser les textes :\n",
    "- Suppression du HTML et des URLs\n",
    "- Mise en minuscules\n",
    "- Lemmatisation (réduction à la racine)\n",
    "- Suppression des stopwords et tokens non alphabétiques\n",
    "\n",
    "Ce prétraitement réduit la dimensionnalité et améliore la qualité des features pour le modèle."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def clean_and_tokenize(text):\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    text = re.sub(r'http\\S+', ' ', text).lower().strip()\n",
    "    doc = nlp(text)\n",
    "    return \" \".join(tok.lemma_ for tok in doc if tok.is_alpha and not tok.is_stop)\n",
    "\n",
    "df['Clean'] = df['description'].apply(clean_and_tokenize)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Séparation train/validation\n",
    "\n",
    "On sépare les données en un ensemble d'entraînement (80%) et de validation (20%) pour évaluer la capacité de généralisation du modèle. On stratifie pour conserver la proportion des classes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df['Clean'], df['Category'],\n",
    "    test_size=0.2, stratify=df['Category'], random_state=42\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline et optimisation par GridSearchCV\n",
    "\n",
    "On construit un pipeline combinant la vectorisation TF-IDF et un SVM linéaire. On utilise GridSearchCV pour tester plusieurs combinaisons d'hyperparamètres :\n",
    "- ngram_range, min_df, max_df pour TF-IDF\n",
    "- C et class_weight pour le SVM\n",
    "\n",
    "La validation croisée (cv=5) permet de sélectionner les meilleurs paramètres selon le score macro-F1."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"clf\", LinearSVC(dual=False, max_iter=5000))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
    "    \"tfidf__min_df\": [3, 5, 10],\n",
    "    \"tfidf__max_df\": [0.8, 0.9, 1.0],\n",
    "    \"clf__C\": [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    \"clf__class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "scorer = make_scorer(f1_score, average=\"macro\")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline, param_grid,\n",
    "    cv=5, n_jobs=-1, scoring=scorer, verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Évaluation sur la validation\n",
    "\n",
    "On prédit les classes sur l'ensemble de validation et on affiche un rapport de classification (précision, rappel, F1-score). Cela permet de vérifier la performance réelle du modèle optimisé."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_val_pred = grid.predict(X_val)\n",
    "print(\"=== Rapport sur le set de validation ===\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prédiction sur les données de test\n",
    "\n",
    "On applique le même nettoyage et la même vectorisation aux textes de test, puis on prédit la catégorie pour chaque texte."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "with open('test.json','r',encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "test_df = pd.DataFrame(test_data).fillna({'description':\"\"})\n",
    "test_df['Clean'] = test_df['description'].apply(clean_and_tokenize)\n",
    "preds = grid.predict(test_df['Clean'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Génération du fichier de soumission\n",
    "\n",
    "On prépare le fichier de soumission au format attendu, associant chaque Id de test à la catégorie prédite."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "template = pd.read_csv('template_submissions.csv')\n",
    "mapping = dict(zip(test_df['Id'], preds))\n",
    "template['Category'] = template['Id'].map(mapping)\n",
    "template.to_csv('submission_svm_tuned.csv', index=False)\n",
    "print(\" Soumission enregistrée : submission_svm_tuned.csv\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concepts mathématiques et conclusion\n",
    "\n",
    "- **TF-IDF** : $tfidf(w, d) = tf(w, d) \\times \\log\\left(\\frac{N}{df(w)}\\right)$\n",
    "- **SVM** : maximise la marge entre les classes dans l'espace vectoriel.\n",
    "- **GridSearchCV** : sélectionne les meilleurs hyperparamètres par validation croisée.\n",
    "- **Macro-F1** : équilibre la performance sur toutes les classes, même rares.\n",
    "\n",
    "Ce pipeline montre comment combiner prétraitement, vectorisation, optimisation et classification pour obtenir un modèle robuste et performant sur des textes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}