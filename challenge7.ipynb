{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de texte avec TF-IDF et RandomForest\n",
    "\n",
    "Ce notebook détaille un pipeline complet de classification de texte utilisant le prétraitement linguistique avec SpaCy, la vectorisation TF-IDF et un modèle RandomForest. Chaque étape est expliquée, du nettoyage à la génération du fichier de soumission.\n",
    "\n",
    "---\n",
    "\n",
    "## Concepts clés\n",
    "\n",
    "- **TF-IDF (Term Frequency-Inverse Document Frequency)** : transforme chaque texte en un vecteur de nombres, reflétant l'importance des mots dans le corpus.\n",
    "- **RandomForestClassifier** : algorithme d'ensemble basé sur la combinaison de plusieurs arbres de décision, robuste et efficace pour la classification.\n",
    "- **Prétraitement linguistique** : nettoyage, lemmatisation, suppression des stopwords pour améliorer la qualité des features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et nettoyage des données\n",
    "\n",
    "On charge les données d'entraînement depuis un fichier JSON. On remplace les valeurs manquantes dans la colonne 'description' par une chaîne vide pour éviter les erreurs lors du traitement."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "with open('train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "df = pd.DataFrame(train_data)\n",
    "df['description'] = df['description'].fillna(\"\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prétraitement linguistique avec SpaCy\n",
    "\n",
    "On utilise SpaCy pour nettoyer et lemmatiser les textes :\n",
    "- Suppression du HTML et des URLs\n",
    "- Mise en minuscules\n",
    "- Lemmatisation (réduction à la racine)\n",
    "- Suppression des stopwords et tokens non alphabétiques\n",
    "\n",
    "Ce prétraitement réduit la dimensionnalité et améliore la qualité des features pour le modèle."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def clean_and_tokenize(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "    text = text.lower().strip()\n",
    "    doc = nlp(text)\n",
    "    tokens = [tok.lemma_ for tok in doc if tok.is_alpha and not tok.is_stop]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['Clean'] = df['description'].apply(clean_and_tokenize)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chargement des labels\n",
    "\n",
    "On associe à chaque texte sa catégorie cible pour l'apprentissage supervisé."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "labels_df = pd.read_csv('train_label.csv')\n",
    "df = df.merge(labels_df, on='Id')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vectorisation des textes avec TF-IDF\n",
    "\n",
    "On transforme les textes en vecteurs de nombres avec `TfidfVectorizer` :\n",
    "- Chaque texte devient un vecteur de taille `max_features` (ici 20 000)\n",
    "- Chaque dimension correspond à un mot ou une paire de mots (n-grammes)\n",
    "- La valeur est le score TF-IDF du mot dans le texte\n",
    "\n",
    "Mathématiquement, le TF-IDF d'un mot $w$ dans un document $d$ est :\n",
    "$$ \\text{tfidf}(w, d) = tf(w, d) \\times \\log\\left(\\frac{N}{df(w)}\\right) $$\n",
    "où $tf(w, d)$ est la fréquence du mot dans le document, $N$ le nombre total de documents, $df(w)$ le nombre de documents contenant $w$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tfidf = TfidfVectorizer(max_features=20000, ngram_range=(1,2), min_df=5, norm='l2')\n",
    "X_tfidf = tfidf.fit_transform(df['Clean'])\n",
    "y = df['Category']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Séparation train/validation\n",
    "\n",
    "On sépare les données en un ensemble d'entraînement (80%) et de validation (20%) pour évaluer la capacité de généralisation du modèle. On stratifie pour conserver la proportion des classes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entraînement du modèle RandomForest\n",
    "\n",
    "Le RandomForest est un ensemble d'arbres de décision. Chaque arbre vote pour une classe, et la classe majoritaire est choisie. Cela permet de réduire le surapprentissage et d'améliorer la robustesse.\n",
    "\n",
    "- `n_estimators=200` : nombre d'arbres\n",
    "- `max_depth=30` : profondeur maximale des arbres\n",
    "- `n_jobs=-1` : utilise tous les cœurs du processeur pour accélérer l'entraînement\n",
    "\n",
    "Mathématiquement, chaque arbre partitionne l'espace des features, et la forêt combine les décisions pour une meilleure généralisation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=30, random_state=42, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_val)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Évaluation du modèle\n",
    "\n",
    "On prédit les classes sur l'ensemble de validation et on affiche un rapport de classification (précision, rappel, F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(classification_report(y_val, y_pred))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prédiction sur les données de test\n",
    "\n",
    "On applique le même prétraitement et la même vectorisation aux textes de test, puis on prédit la catégorie pour chaque texte."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Chargement des données de test\n",
    "with open('test.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df['description'] = test_df['description'].fillna(\"\")\n",
    "test_df['Clean'] = test_df['description'].apply(clean_and_tokenize)\n",
    "X_test = tfidf.transform(test_df['Clean'])\n",
    "preds = rf_clf.predict(X_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Génération du fichier de soumission\n",
    "\n",
    "On prépare le fichier de soumission au format attendu, associant chaque Id de test à la catégorie prédite."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "template = pd.read_csv('template_submissions.csv')\n",
    "template['Category'] = template['Id'].map(dict(zip(test_df['Id'], preds)))\n",
    "template.to_csv('submission_rf.csv', index=False)\n",
    "print(\"Fichier de soumission enregistré : 'submission_rf.csv'\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concepts mathématiques et conclusion\n",
    "\n",
    "- **TF-IDF** : pondère l'importance des mots selon leur fréquence dans le document et leur rareté dans le corpus.\n",
    "- **RandomForest** : combine plusieurs arbres de décision pour améliorer la robustesse et la généralisation.\n",
    "- **Classification** : la sortie du modèle est la classe avec la majorité des votes des arbres.\n",
    "\n",
    "Ce pipeline montre comment passer de textes bruts à des prédictions de classes avec un modèle d'ensemble, en utilisant des représentations vectorielles robustes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}